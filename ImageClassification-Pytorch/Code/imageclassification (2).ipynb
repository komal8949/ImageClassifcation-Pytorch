{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYBS_Hd-2E2i"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow[and-cuda]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR-zYgAnl-mt",
        "outputId": "f06da981-fcf9-485b-dcc8-37beb8aa664b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEQIr4kPKufV",
        "outputId": "21d6d238-ee8b-4716-9bec-869767349853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Nov 25 06:46:56 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRzlC-mL26aj",
        "outputId": "284de3f0-0517-454d-975f-394f32e2010a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/version/__init__.py'>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVfEKqZfMy-_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Lambda,Flatten, Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckwxJvFy_yQA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_path= \"/drive/MyDrive/project/train\"\n",
        "test_path=\"/drive/MyDrive/project/test\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irWyjzu6hlSJ"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [299,299]\n",
        "num_classes=5\n",
        "batch_size=32\n",
        "learning_rate=0.001\n",
        "epochs=15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb8dwXdQkjsp"
      },
      "outputs": [],
      "source": [
        "train_datagen= ImageDataGenerator(rescale=1./255,\n",
        "                                            shear_range=0.2,\n",
        "                                            zoom_range=0.2,\n",
        "                                            horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKBty5KSlCmy"
      },
      "outputs": [],
      "source": [
        "valid_datagen=ImageDataGenerator(rescale=1./255\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7jUJh1xlZzJ",
        "outputId": "3e008383-4882-4e71-9c31-de90ae6a4d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model= InceptionV3(input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3),weights=\"imagenet\",include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E19gnYjUlHdB"
      },
      "outputs": [],
      "source": [
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x= Dense(1024,activation='relu')(x)\n",
        "prediction=Dense(num_classes,activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5m107XAmvCn"
      },
      "outputs": [],
      "source": [
        "model=Model(inputs=base_model.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxoGZ7VYnDGK"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qJRkXdGmPnG"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=learning_rate),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1NnovdToI0d",
        "outputId": "79772fd8-b3fe-4443-c58b-8ee456020c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 104 images belonging to 5 classes.\n",
            "Found 36 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator=train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "valid_generator=valid_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVMmWXlqpG55"
      },
      "source": [
        "**training thr model\n",
        "**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLcO5CocntgY",
        "outputId": "6ee65f29-d490-426f-85e1-39ae4a945775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 21s/step - accuracy: 0.2429 - loss: 2.8103 - val_accuracy: 0.2500 - val_loss: 2.2398\n",
            "Epoch 2/15\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.4062 - loss: 1.9465"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.4062 - loss: 1.9465 - val_accuracy: 0.2500 - val_loss: 1.9562\n",
            "Epoch 3/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.4854 - loss: 1.3370\n",
            "Epoch 4/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - accuracy: 0.7188 - loss: 0.8050 - val_accuracy: 0.7500 - val_loss: 0.5988\n",
            "Epoch 5/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.8056 - loss: 0.5728 - val_accuracy: 0.5000 - val_loss: 2.3524\n",
            "Epoch 6/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5312 - loss: 1.4009 \n",
            "Epoch 7/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 526ms/step - accuracy: 0.7804 - loss: 0.7012 - val_accuracy: 0.7188 - val_loss: 0.6138\n",
            "Epoch 8/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.4310 - val_accuracy: 1.0000 - val_loss: 0.1829\n",
            "Epoch 9/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.8222 - loss: 0.4040   \n",
            "Epoch 10/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.7500 - loss: 0.5091 - val_accuracy: 0.7812 - val_loss: 0.5067\n",
            "Epoch 11/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.8889 - loss: 0.2977 - val_accuracy: 1.0000 - val_loss: 0.0378\n",
            "Epoch 12/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.9062 - loss: 0.2617\n",
            "Epoch 13/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 422ms/step - accuracy: 0.9387 - loss: 0.2334 - val_accuracy: 0.8125 - val_loss: 0.5568\n",
            "Epoch 14/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8438 - loss: 0.3183 - val_accuracy: 1.0000 - val_loss: 0.0932\n",
            "Epoch 15/15\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 0.9779 - loss: 0.1264\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.n // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd31TzLFpOVJ",
        "outputId": "d80cab9f-f53a-4743-a481-a7eecedae43a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('/drive/MyDrive/imageclassification.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQXcVF0vr0xA"
      },
      "source": [
        "**testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "QvLjPGPprzGB",
        "outputId": "8a0c9925-9b68-456b-fa77-2f27ec26ef07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f5864a46-c14e-43f6-aa0b-6a0974b68d97\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f5864a46-c14e-43f6-aa0b-6a0974b68d97\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import PIL.Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = tf.keras.models.load_model('/drive/MyDrive/imageclassification.h5')\n",
        "\n",
        "class_labels=['gracy','janish','komal','riya','tyagi']\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "uploaded_file_path= list(uploaded.keys())[0]\n",
        "\n",
        "\n",
        "def predict_dost(image_path):\n",
        "    processed_image= preprocess_image(image_path)\n",
        "    predictions= model.predict(processed_image)\n",
        "    predicted_label= class_labels[np.argmax(predictions)]\n",
        "    confidence= np.max(predictions)\n",
        "    return predicted_label, confidence\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img= PIL.Image.open(image_path)\n",
        "    img= img.resize((299,299))\n",
        "    img= np.array(img)/ 255.0\n",
        "    img= np.expand_dims(img,axis=0)\n",
        "    return img\n",
        "\n",
        "prediction, confidence=predict_dost(uploaded_file_path)\n",
        "\n",
        "\n",
        "img= PIL.Image.open(uploaded_file_path)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f'Prediction: {prediction}\\nConfidence: {confidence:.2%}')\n",
        "plt.show()\n",
        "\n",
        "# def preprocess_image(image_path):\n",
        "#     img= PIL.Image.open(image_path)\n",
        "#     img= img.resize((299,299))\n",
        "#     img= np.array(img)/ 255.0\n",
        "#     img= np.expand_dims(img,axis=0)\n",
        "#     return img\n",
        "\n",
        "\n",
        "# def predict_dost(image_path):\n",
        "#     processed_image= preprocess_image(image_path)\n",
        "#     predictions= model.predict(processed_image)\n",
        "#     predicted_label= class_labels[np.argmax(predictions)]\n",
        "#     confidence= np.max(predictions)\n",
        "#     return predicted_label, confidence\n",
        "\n",
        "\n",
        "#     from google.colab import files\n",
        "#     uploaded = files.upload()\n",
        "\n",
        "\n",
        "#     uploaded_file_path= list(uploaded.keys())[0]\n",
        "\n",
        "\n",
        "#     prediction, confidence=predict_dost(uploaded_file_path)\n",
        "\n",
        "\n",
        "#     img= PIL.Image.open(uploaded_file_path)\n",
        "#     plt.imshow(img)\n",
        "#     plt.axis('off')\n",
        "#     plt.title(f'Prediction: {prediction}\\nConfidence: {confidence:.2%}')\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LYx4IdVJUGc"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "SAe_qFM1JUGj",
        "outputId": "252d5124-4466-41a4-bdf2-abc78b10f30b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"from IPython.display import Image\\ntry:\\n  filename = take_photo()\\n  print('Saved to {}'.format(filename))\\n\\n  # Show the image which was just taken.\\n  display(Image(filename))\\nexcept Exception as err:\\n  # Errors will be thrown if the user does not have a webcam or if they do not\\n  # grant the page permission to access it.\\n  print(str(err))\\n\\ndef predict_dost():\\n    processed_image= preprocess_image(image_path)\\n    predictions= model.predict(processed_image)\\n    predicted_label= class_labels[np.argmax(predictions)]\\n    confidence= np.max(predictions)\\n    return predicted_label, confidence\\n\\n\\n\\ndef preprocess_image(image_path):\\n    img= PIL.Image.open(image_path)\\n    img= img.resize((299,299))\\n    img= np.array(img)/ 255.0\\n    img= np.expand_dims(img,axis=0)\\n    return img\\n\\nprediction, confidence=predict_dost(uploaded_file_path)\\n\\n\\nimg= PIL.Image.open(uploaded_file_path)\\nplt.imshow(img)\\nplt.axis('off')\\nplt.title(f'Prediction: {prediction}\\nConfidence: {confidence:.2%}')\\nplt.show()\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))\n",
        "\n",
        "def predict_dost():\n",
        "    processed_image= preprocess_image(image_path)\n",
        "    predictions= model.predict(processed_image)\n",
        "    predicted_label= class_labels[np.argmax(predictions)]\n",
        "    confidence= np.max(predictions)\n",
        "    return predicted_label, confidence\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img= PIL.Image.open(image_path)\n",
        "    img= img.resize((299,299))\n",
        "    img= np.array(img)/ 255.0\n",
        "    img= np.expand_dims(img,axis=0)\n",
        "    return img\n",
        "\n",
        "prediction, confidence=predict_dost(uploaded_file_path)\n",
        "\n",
        "\n",
        "img= PIL.Image.open(uploaded_file_path)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f'Prediction: {prediction}\\nConfidence: {confidence:.2%}')\n",
        "plt.show()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOGvDp0ZKEAn"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))\n",
        "\n",
        "def predict_dost(image):\n",
        "    processed_image= preprocess_image(image)\n",
        "    predictions= model.predict(processed_image)\n",
        "    predicted_label= class_labels[np.argmax(predictions)]\n",
        "    confidence= np.max(predictions)\n",
        "    return predicted_label, confidence\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    img= PIL.Image.open(filename)\n",
        "    img= img.resize((299,299))\n",
        "    img= np.array(img)/ 255.0\n",
        "    img= np.expand_dims(img,axis=0)\n",
        "    return img\n",
        "\n",
        "prediction, confidence=predict_dost(image)\n",
        "\n",
        "\n",
        "img= PIL.Image.open(filename)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f'Prediction: {prediction}\\nConfidence: {confidence:.2%}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMMCwwrlmJTJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}